{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving stochastic resources-constrainded project scheduling problems with a Neural Network based on Reinforcement Learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # regex\n",
    "from random import random, shuffle, choice\n",
    "from itertools import chain, combinations, compress\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the input DataFrames\n",
    "* a DataFrame *general_df* for general project data (link to base data and inital value generator)\n",
    "* a DataFrame *project_df* with project data, like number of jobs and the due date\n",
    "* a DataFrame *resources_df* which is a list of all resources and their limits\n",
    "* a DataFrame *df* that contains all the network info: all nodes with their successors and predecessors, their duration, etc.\n",
    "* a DataFrame *limits* that is used to keep track of available resources and resources in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'D:\\Gregor\\Dropbox\\Studium\\j120.sm\\j12060_9.sm'\n",
    "path = r'C:\\Users\\webgr_000\\Dropbox\\Studium\\[M04] - WS 2018-2019\\Thesis\\Test Sets\\J30\\J30.sm\\j301_1.sm'\n",
    "#path = r'D:\\Gregor\\Dropbox\\Studium\\[M04] - WS 2018-2019\\Thesis\\Test Sets\\J30\\J30.sm\\j301_1.sm'\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = {}\n",
    "for line in file[1:3]:\n",
    "    l = list(map(str.strip, line.split(sep = ':')))\n",
    "    general[l[0]] = l[1]\n",
    "\n",
    "project = {}\n",
    "for line in file[4:7]:\n",
    "    l = list(map(str.strip, line.split(sep = ':')))\n",
    "    project[l[0]] = l[1]\n",
    "\n",
    "info = (list(map(str.split, file[13:15])))\n",
    "for i in range(len(info[0])):\n",
    "    project[info[0][i]] = info[1][i]\n",
    "\n",
    "general_df = pd.DataFrame.from_dict(general, orient='index', columns=['value'])\n",
    "project_df = pd.DataFrame.from_dict(project, orient='index', columns=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sep = re.compile('[RND][ \\d]{2}|[\\d]+') # regex pattern to extract the resources\n",
    "resources = {}\n",
    "for line in file[8:11]:\n",
    "    l = list(map(str.strip, line.replace('-', '').split(sep = ':')))\n",
    "    resources[l[0]] = l[1][0]\n",
    "res = [re.findall(res_sep, file[-3]), re.findall(res_sep, file[-2])]\n",
    "for i, r in enumerate(res[0]):\n",
    "    resources[r] = res[1][i]\n",
    "resources_df = pd.DataFrame.from_dict(resources, orient='index', columns=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = re.compile('[*]+') # regex pattern to find the end of a block; blocks are seperated by a row of ****\n",
    "dur_sep = re.compile('[RND][ \\d]{2}|[\\w.]+')\n",
    "\n",
    "relations = []\n",
    "idx = 17 # start index to find the precedence relations\n",
    "while not re.findall(sep, file[idx]):\n",
    "    relations.append(file[idx])\n",
    "    idx += 1\n",
    "\n",
    "durations = []\n",
    "idx = idx + 4 # start index to find the task's durations. They start four lines after the relations block.\n",
    "header = re.findall(dur_sep, file[idx - 2])\n",
    "while not re.findall(sep, file[idx]):\n",
    "    durations.append(file[idx].strip().split())\n",
    "    idx += 1\n",
    "durations_df = pd.DataFrame(durations, columns=header)\n",
    "\n",
    "relations_df = pd.DataFrame(columns=relations[0].split())\n",
    "for i, rel in enumerate(map(str.split, relations[1:])):\n",
    "    relations_df.loc[i] = [rel[0], rel[1], rel[2], list(map(int, rel[3:]))]\n",
    "\n",
    "# now merge/join both DataFrames and set the columns types to numeric (when possible)\n",
    "df = relations_df.merge(durations_df, how='right', on='jobnr.')\n",
    "df.set_index('jobnr.', inplace=True)\n",
    "\n",
    "# find all the successors and add them as a new column to each state\n",
    "succ = {'1':[]}\n",
    "for index, row in df.iterrows():\n",
    "    for successor in row['successors']:\n",
    "        if str(successor) in succ:\n",
    "            succ[str(successor)].append(int(index))\n",
    "        else:\n",
    "            succ[str(successor)] = [int(index)]\n",
    "df['predecessors'] = df.index.map(succ)\n",
    "\n",
    "df.index = df.index.map(int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limits(resources_df):\n",
    "    limits = pd.concat([resources_df.iloc[3:], resources_df.iloc[3:]], axis = 1)\n",
    "    limits.columns = ['limits', 'available']\n",
    "    return limits.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
