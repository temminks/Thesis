{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # regex\n",
    "import time\n",
    "from random import random\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the input DataFrames\n",
    "* a DataFrame *general_df* for general project data (link to base data and inital value generator)\n",
    "* a DataFrame *project_df* with project data, like number of jobs and the due date\n",
    "* a DataFrame *resources_df* which is a list of all resources and their limits\n",
    "* a DataFrame *df* that contains all the network info: all nodes with their successors and predecessors, their duration, etc.\n",
    "* a DataFrame *limits* that is used to keep track of available resources and resources in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'D:\\Gregor\\Dropbox\\Studium\\j120.sm\\j12060_9.sm'\n",
    "#path = r'C:\\Users\\webgr_000\\Dropbox\\Studium\\[M04] - WS 2018-2019\\Thesis\\Test Sets\\J30\\J30.sm\\j301_1.sm'\n",
    "path = r'D:\\Gregor\\Dropbox\\Studium\\[M04] - WS 2018-2019\\Thesis\\Test Sets\\J30\\J30.sm\\j301_1.sm'\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = {}\n",
    "for line in file[1:3]:\n",
    "    l = list(map(str.strip, line.split(sep = ':')))\n",
    "    general[l[0]] = l[1]\n",
    "\n",
    "project = {}\n",
    "for line in file[4:7]:\n",
    "    l = list(map(str.strip, line.split(sep = ':')))\n",
    "    project[l[0]] = l[1]\n",
    "\n",
    "info = (list(map(str.split, file[13:15])))\n",
    "for i in range(len(info[0])):\n",
    "    project[info[0][i]] = info[1][i]\n",
    "\n",
    "general_df = pd.DataFrame.from_dict(general, orient='index', columns=['value'])\n",
    "project_df = pd.DataFrame.from_dict(project, orient='index', columns=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sep = re.compile('[RND][ \\d]{2}|[\\d]+') # regex pattern to extract the resources\n",
    "resources = {}\n",
    "for line in file[8:11]:\n",
    "    l = list(map(str.strip, line.replace('-', '').split(sep = ':')))\n",
    "    resources[l[0]] = l[1][0]\n",
    "res = [re.findall(res_sep, file[-3]), re.findall(res_sep, file[-2])]\n",
    "for i, r in enumerate(res[0]):\n",
    "    resources[r] = res[1][i]\n",
    "resources_df = pd.DataFrame.from_dict(resources, orient='index', columns=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = re.compile('[*]+') # regex pattern to find the end of a block; blocks are seperated by a row of ****\n",
    "dur_sep = re.compile('[RND][ \\d]{2}|[\\w.]+')\n",
    "\n",
    "relations = []\n",
    "idx = 17 # start index to find the precedence relations\n",
    "while not re.findall(sep, file[idx]):\n",
    "    relations.append(file[idx])\n",
    "    idx += 1\n",
    "\n",
    "durations = []\n",
    "idx = idx + 4 # start index to find the task's durations. They start four lines after the relations block.\n",
    "header = re.findall(dur_sep, file[idx - 2])\n",
    "while not re.findall(sep, file[idx]):\n",
    "    durations.append(file[idx].strip().split())\n",
    "    idx += 1\n",
    "durations_df = pd.DataFrame(durations, columns=header)\n",
    "\n",
    "relations_df = pd.DataFrame(columns=relations[0].split())\n",
    "for i, rel in enumerate(map(str.split, relations[1:])):\n",
    "    relations_df.loc[i] = [rel[0], rel[1], rel[2], list(map(int, rel[3:]))]\n",
    "\n",
    "# now merge/join both DataFrames and set the columns types to numeric (when possible)\n",
    "df = relations_df.merge(durations_df, how='right', on='jobnr.')\n",
    "df.set_index('jobnr.', inplace=True)\n",
    "\n",
    "# find all the successors and add them as a new column to each state\n",
    "succ = {'1':[]}\n",
    "for index, row in df.iterrows():\n",
    "    for successor in row['successors']:\n",
    "        if str(successor) in succ:\n",
    "            succ[str(successor)].append(int(index))\n",
    "        else:\n",
    "            succ[str(successor)] = [int(index)]\n",
    "df['predecessors'] = df.index.map(succ)\n",
    "\n",
    "df.index = df.index.map(int)\n",
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limits(resources_df):\n",
    "    limits = pd.concat([resources_df.iloc[3:], resources_df.iloc[3:]], axis = 1)\n",
    "    #limits.columns = ['limits', 'available']\n",
    "    return limits.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of hyperparameter functions\n",
    "* greediness *epsilon*\n",
    "* rewards\n",
    "* learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meyl uses different greediness parameters Îµ during theses phases. We define the function to determine the parameter:\n",
    "\n",
    "$$\\epsilon(n)=\\left\\{\\begin{array}{ll} \\varepsilon_s, & 0 \\leq n \\leq n_s \\\\\n",
    "              \\frac{\\varepsilon_f - \\varepsilon_s}{n_m}(n - n_s) + \\varepsilon_s & n_s < n \\leq n_s + n_m \\text{, with } f_\\varepsilon = 0 \\\\\n",
    "              \\varepsilon_m & n_s < n \\leq n_s + n_m \\text{, with } f_\\varepsilon = 1 \\\\\n",
    "              0 & n_s + n_m < n \\leq n_{max} \\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(n, function_type=0, eps_m=0):\n",
    "    '''\n",
    "    Returns the value of the greediness parameter epsilon that depends on the phase\n",
    "    (exploration, learning, convergence) of the algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    function_type: choose 0 for a constantly decaying and 1 for a constant value eps_m\n",
    "    '''\n",
    "    if 0 <= n <= n_s:\n",
    "        return eps_s\n",
    "    elif n_s < n <= n_m:\n",
    "        if function_type:\n",
    "            return eps_m\n",
    "        else:\n",
    "            return (((eps_f - eps_s) / n_m) * (n - n_s) + eps_s)\n",
    "    elif n_m < n <= n_max:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reward function can use known project durations *t_min* and *t_max* to encourage the algorithm to improve good solutions even more.\n",
    "\n",
    "$$r(t)=\\left\\{\\begin{array}{ll} 1 - \\left(\\frac{t - t_{min}}{t_{max}}\\right)^{0,4} & f_r = 0 \\\\\n",
    "              \\frac{t - t_{max}}{t_{min} - t_{max}} & f_r = 1 \\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(t, function_type=0):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    function_type: if the times t_min and t_max are unknown choose type 1 and calculate the\n",
    "                    times manually by running a couple of random iterations\n",
    "    '''\n",
    "    if function_type:\n",
    "        return (t - t_max) / (t_min - t_max)\n",
    "    else:\n",
    "        return 1 - ((t - t_min) / t_max)**0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meyl implements two different types of learning rates: one uses a constant value around 0.01 and one uses a learning rate that decays linearly during the convergence phase (during (*n_s + n_m*) and *n_max*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(n, function_type=0, alpha_f=0):\n",
    "    '''\n",
    "    Returns the learning rate alpha that is either a constant value alpha_b\n",
    "    or can be chosen to decay during the convergence phase (for n > n_m + n_s).\n",
    "    function_type -> choose 0 for a function that linearly decays from alpha_b\n",
    "                     to a final value alpha_f during the convergence phase or\n",
    "                     choose 1 for the constant value alpha_b.\n",
    "    '''\n",
    "    if 0 <= n <= n_m:\n",
    "        return alpha_b\n",
    "    elif n_m < n <= n_max:\n",
    "        if function_type:\n",
    "            return (((alhpha_b - alpha_f) / (n_m - n_max)) * (n - n_max)) + alpha_f\n",
    "        else:\n",
    "            return alpha_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_from_single_states(limits, finished_jobs, running_jobs, df):\n",
    "    '''\n",
    "    '''\n",
    "    if epsilon(n, function_type=1, eps_m=0.2) < random():\n",
    "        recorded_actions = actions.loc[(actions.possibleJobs ==\n",
    "                    tuple(sorted(get_possible_jobs_from_single_states(finished_jobs, df)))) &\n",
    "                    (actions.runningJobs == tuple(sorted(running_jobs.keys())))]\n",
    "        if len(recorded_actions) > 0:\n",
    "            return actions.loc[recorded_actions['q'].idxmax()].action\n",
    "\n",
    "    feasible_actions = []\n",
    "    # possible jobs are those that could be started because all their predecessors have been finished\n",
    "    possible_actions = get_possible_jobs_from_single_states(finished_jobs, df)\n",
    "    # we select only those actions that do not consume more resources than available from the possible_actions list \n",
    "    shuffled_actions = [key for key in possible_actions if min(limits.available.subtract(df.loc[key][limits.index])) >= 0]\n",
    "    if len(shuffled_actions) > 0:\n",
    "        shuffle(shuffled_actions)\n",
    "        feasible_actions.append(shuffled_actions[0])\n",
    "\n",
    "        for i in range(1, len(shuffled_actions)):\n",
    "            # if we can add yet another activity from the shuffled_actions-list without using more resources than available\n",
    "            # then add this activity to the feasible_actions-list.\n",
    "            if min([x1 - x2 for (x1, x2) in zip(limits.available, [sum(row[column] for\n",
    "                row in [df.loc[action][limits.index] for action in feasible_actions] +\n",
    "                [list(df.loc[shuffled_actions[i]][limits.index])]) for column in range(len(limits.index))])]) >= 0:\n",
    "                feasible_actions.append(shuffled_actions[i])\n",
    "\n",
    "    return feasible_actions\n",
    "\n",
    "def get_possible_jobs_from_single_states(finished_jobs, df):\n",
    "    '''\n",
    "    '''\n",
    "    return set(chain(*[get_possible_jobs(job, finished_jobs, df) for job\n",
    "                       in finished_jobs])) - set(running_jobs.keys()) - set(finished_jobs)\n",
    "\n",
    "def get_possible_jobs(key, finished_jobs, df):\n",
    "    '''\n",
    "    A job can only be started when all of its predecessors are finished. This method returns - based on the job with id\n",
    "    key and a list of already finished jobs - the jobs that could possibly be started.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key: a job id\n",
    "    finished_jobs: a list of finished jobs\n",
    "    df: the DataFrame with info about all jobs to get a job's successors and predecessors\n",
    "    '''\n",
    "    return [i for i in df.loc[key].successors if all(j in finished_jobs for j in df.loc[i].predecessors)]\n",
    "\n",
    "def print_summary(t, n):\n",
    "    '''\n",
    "    Prints a small summary about the current status.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t: current time step\n",
    "    n: the summary is printed each n time steps\n",
    "    '''\n",
    "    if t%n == 0 and t>0:\n",
    "        print('iteration', t)\n",
    "        print('running:', running_jobs)\n",
    "        print('finished:', finished_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run a whole iteration\n",
    "I will define all variables, initialise the problem and use the functions that were defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_s, eps_m, eps_f = 1, 0.2, 0.05\n",
    "alpha_b = 0.1 # function_type = 0 -> constant value\n",
    "n, n_max = 0, 1000\n",
    "n_s, n_m = 0.03*n_max, 0.85*n_max\n",
    "t_min, t_max = 44, 68\n",
    "actions = pd.DataFrame(columns = ['possibleJobs', 'runningJobs', 'action', 'q'])\n",
    "limits = get_limits(resources_df)\n",
    "time_steps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataFrame *actions* keeps track of all the actions and is references by the q-table\n",
    "* Dictionary *states* contains all states that are finished and the jobs that can be started in that state\n",
    "* Dictionary *running_jobs* is used as a counter to calculate the remaining time until a job is finished\n",
    "* List *finished_jobs* contains all finished jobs - a job can be started when all of its predecessors are in the finished_jobs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'available'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-73717b9a3946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# free ressources if the task is finished and remove the task from the list of running jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrunning_jobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mlimits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlimits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mrunning_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mfinished_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'available'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "while n <= n_max:\n",
    "    # initialisation\n",
    "    t = 0\n",
    "    running_jobs = {1:0}\n",
    "    finished_jobs = []\n",
    "    current_actions = pd.DataFrame(columns = ['possibleJobs', 'runningJobs', 'action'])\n",
    "\n",
    "    # run while not all jobs are finished, i.e. while the length of the finished_jobs-list is less than the number of task\n",
    "    while len(finished_jobs) < int(project_df.loc['jobs (incl. supersource/sink )']):\n",
    "        acts = get_actions_from_single_states(limits, finished_jobs, running_jobs, df)\n",
    "        if len(acts) > 0:\n",
    "            current_actions = current_actions.append({\n",
    "                'possibleJobs': tuple(sorted(get_possible_jobs_from_single_states(finished_jobs, df))),\n",
    "                'runningJobs': tuple(sorted(running_jobs.copy().keys())),\n",
    "                'action': tuple(sorted(acts))\n",
    "            }, ignore_index = True)\n",
    "\n",
    "            running_jobs.update({job: df.loc[job].duration for job in acts})\n",
    "            limits.available = limits.available.subtract(\n",
    "                pd.DataFrame(df.loc[key][limits.index] for key in acts).sum(axis='rows'), fill_value=0)\n",
    "\n",
    "        ########################################################\n",
    "        t += 1 # update timer and move on the the next time-step\n",
    "        ########################################################\n",
    "\n",
    "        for key in running_jobs.copy().keys():\n",
    "            running_jobs[key] -= 1\n",
    "\n",
    "            # free ressources if the task is finished and remove the task from the list of running jobs\n",
    "            if running_jobs[key] <= 0:\n",
    "                limits.available = limits.available.add(df.loc[key][limits.index], fill_value=0)\n",
    "                running_jobs.pop(key)\n",
    "                finished_jobs.append(key)\n",
    "\n",
    "    for idx in range(len(current_actions)):\n",
    "        row = current_actions.loc[idx]\n",
    "        actions_row = actions.loc[(actions.possibleJobs == row.possibleJobs) & (actions.runningJobs == row.runningJobs) &\n",
    "            (actions.action == row.action)]\n",
    "        if len(actions_row) == 0:\n",
    "            row['q'] = 0.0\n",
    "            actions = actions.append(row, ignore_index=True)\n",
    "\n",
    "        actions.loc[actions_row.index, 'q'] += learning_rate(n)**(len(current_actions) - idx) * (reward(t, function_type=1) - actions.loc[actions_row.index, 'q'])\n",
    "\n",
    "    print_summary(t, 100)\n",
    "    time_steps.append(t)\n",
    "    n += 1\n",
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
